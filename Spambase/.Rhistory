# Flush r-studio and set working directory
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
set.seed(0)
install.packages("devtools")
library(devtools)
install_github("komorowskilab/R.ROSETTA")
library(R.ROSETTA)
install.packages("dplyr")
# load necessary packages
library(dplyr)
library(R.ROSETTA)
if (!requireNamespace("arules", quietly = TRUE)) install.packages("arules")
# Load necessary packages
library(arules)
# Load the dataset
spambase_data <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/spambase_train2_labeled.csv", colClasses = "character")
# Change names of truth and prediction
names(spambase_data)[dim(spambase_data)[2] - 1] = "True"
names(spambase_data)[dim(spambase_data)[2]] = "Prediction"
# Extract true labels
truth <- spambase_data[,(dim(spambase_data)[2] - 1)]
# Remove truth label from data frame
df <- spambase_data[,c(1:(dim(spambase_data)[2] - 2), dim(spambase_data)[2])]
# Determine which columns are continuous and need binning
continuous_columns <- colnames(df)[1:(ncol(df) - 1)]
# Convert columns to numeric if they are not already
for (col in continuous_columns) {
df[[col]] <- as.numeric(df[[col]])
}
df[[col]] <- discretize(df[[col]], method = "frequency", breaks = 3)  # Adjust the number of breaks as needed
# Apply equal frequency binning to each continuous column
for (col in continuous_columns) {
df[[col]] <- discretize(df[[col]], method = "frequency", breaks = 3)  # Adjust the number of breaks as needed
}
# Display the first few rows of the discretized dataset to verify the changes
head(df)
# create reversed data frame and data frame containing positions 85-89
rev_df <- dat[,c((dim(dat)[2] - 2):1, dim(dat)[2])]
# Load the dataset
spambase_data <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/spambase_train2_labeled.csv", colClasses = "character")
# Change names of truth and prediction
names(spambase_data)[ncol(spambase_data) - 1] <- "True"
names(spambase_data)[ncol(spambase_data)] <- "Prediction"
# Extract true labels and remove truth label from data frame
truth <- spambase_data$True
df <- spambase_data[, -which(names(spambase_data) == "True")]
# Determine which columns are continuous and need binning
continuous_columns <- colnames(df)[sapply(df, is.numeric)]  # Assuming numeric columns are continuous
# Convert columns to numeric if they are not already
df[continuous_columns] <- lapply(df[continuous_columns], as.numeric)
# Apply equal frequency binning to each continuous column with custom labels
for (col in continuous_columns) {
quantile_breaks <- quantile(df[[col]], probs = c(0, 1/3, 2/3, 1), na.rm = TRUE)
df[[col]] <- cut(df[[col]], breaks = quantile_breaks, labels = c("Low", "Medium", "High"), include.lowest = TRUE)
}
# Reattach the true labels
df$True <- truth
# Display the first few rows of the discretized dataset to verify the changes
head(df)
Sys.setenv(PATH = paste("/opt/homebrew/bin", Sys.getenv("PATH"), sep=":"))
system("wine --version")
help rosetta
View(df)
View(spambase_data)
View(df)
# Load the dataset
spambase_data <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/spambase_train2_labeled.csv", colClasses = "character")
# Change names of truth and prediction
names(spambase_data)[ncol(spambase_data) - 1] <- "True"
names(spambase_data)[ncol(spambase_data)] <- "Prediction"
# Extract true labels and remove truth label from data frame
truth <- spambase_data$True
df <- spambase_data[, -which(names(spambase_data) == "True")]
# Determine which columns are continuous and need binning
continuous_columns <- colnames(df)[sapply(df, is.numeric)]  # Assuming numeric columns are continuous
# Convert columns to numeric if they are not already
df[continuous_columns] <- lapply(df[continuous_columns], as.numeric)
# Apply equal frequency binning to each continuous column with custom labels
for (col in continuous_columns) {
quantile_breaks <- quantile(df[[col]], probs = c(0, 1/3, 2/3, 1), na.rm = TRUE)
df[[col]] <- cut(df[[col]], breaks = quantile_breaks, labels = c("Low", "Medium", "High"), include.lowest = TRUE)
}
# Reattach the true labels
df$True <- truth
# Display the first few rows of the discretized dataset to verify the changes
head(df)
# Load the dataset
spambase_data <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/spambase_train2_labeled.csv", colClasses = "character")
# Change names of truth and prediction
names(spambase_data)[ncol(spambase_data) - 1] <- "True"
names(spambase_data)[ncol(spambase_data)] <- "Prediction"
# Extract true labels and remove truth label from data frame
truth <- spambase_data$True
df <- spambase_data[, -which(names(spambase_data) == "True")]
# Determine which columns are continuous and need binning
continuous_columns <- colnames(df)[sapply(df, function(x) !all(x %in% c("", NA)))]
# Convert columns to numeric if they are not already
df[continuous_columns] <- lapply(df[continuous_columns], function(x) as.numeric(as.character(x)))
# Apply equal frequency binning to each continuous column with custom labels
for (col in continuous_columns) {
if (!all(is.na(df[[col]]))) {  # Ensure there are non-NA values to cut
quantile_breaks <- quantile(df[[col]], probs = c(0, 1/3, 2/3, 1), na.rm = TRUE)
df[[col]] <- cut(df[[col]], breaks = quantile_breaks, labels = c("Low", "Medium", "High"), include.lowest = TRUE)
}
}
# Reattach the true labels
df$True <- truth
# Display the first few rows of the discretized dataset to verify the changes
head(df)
# Flush r-studio and set working directory
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
set.seed(0)
# load necessary packages
library(dplyr)
library(R.ROSETTA)
# load data
dat <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Breast_cancer/breastcancer_train2_binned.csv", header = T, colClasses = "character")
# Check column names
print(names(dat))
# Summary to check for any obvious issues in data
summary(dat)
# load data
dat <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Breast_cancer/breastcancer_train2_binned.csv", header = T, colClasses = "character")
View(dat)
# change names of truth and prediction
names(dat)[dim(dat)[2] - 1] = "True"
names(dat)[dim(dat)[2]] = "Prediction"
# extract true labels
truth <- dat[,(dim(dat)[2] - 1)]
View(dat)
# remove truth label from data frame
df <- dat[,c(1:(dim(dat)[2] - 2), dim(dat)[2])]
# run Rosetta on all three data frame
ros <- rosetta(df, discrete = T, underSample = T, reducer = "Johnson")
testie <- recalculateRules(df,ros$main, discrete = T)
testie_rec <- distinct(testie[testie$pValue<=0.05,])
viewRules(testie_rec)
# load test set
test <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Breast_cancer/breastcancer_test_binned.csv", colClasses = "character", header = T)
# extract data and NN label
test_truth <- test[,(dim(test)[2] - 1)]
test_df <- test[,c(1:(dim(test)[2] - 2), dim(test)[2])]
names(test_df)[dim(test_df)[2]] <- "Prediction"
# predict classes for test data
pred <- predictClass(test_df[,1:(dim(test_df)[2] - 1)], testie_rec, discrete = T, validate = T, defClass = test_df[,dim(test_df)[2]], normalizeMethod = "rulnum")
pred$accuracy
table(pred$out[,c("currentClass", "predictedClass")])
pred_test <- predictClass(test_df[,1:(dim(test_df)[2] - 1)], testie_rec, discrete = T, validate = T, defClass = test_df[,dim(test_df)[2]], normalizeMethod = "rulnum")
pred_test$accuracy
table(pred_test$out[,c("currentClass", "predictedClass")])
# extract wrongly classified objects
wrongObj <- which(df[,dim(df)[2]] != truth)
# get supportSet as list
supportSet <- lapply(testie_rec$supportSetRHS, function(x){as.numeric(unlist(strsplit(x, ",")))})
# create heatmap to identify misclassified objects in support set of rules
rules <- list()
for(i in wrongObj){
tmp = which(unlist(lapply(supportSet, function(x){(i %in% x)})))
rules[[length(rules) + 1]] <- as.numeric(row.names(testie_rec[tmp,]))
}
r <- unlist(rules) %>% unique
x = lapply(rules, function(x){as.numeric(r %in% x)}) %>% data.frame
names(x) = wrongObj
row.names(x) <- r
heatmap(as.matrix(x), scale = "none", Colv = F, col = c("white", "black"),
xlab = "Object Number", ylab = "Rule Rank")
View(testie_rec)
viewRules(testie_rec[testie_rec1$decision == 1,])
testie_rec <- distinct(testie[testie$pValue<=0.05,])
viewRules(testie_rec[testie_rec$decision == 1,])
viewRules(testie_rec[testie_rec$decision == 0,])
# Flush r-studio and set working directory
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
set.seed(0)
# load necessary packages
library(dplyr)
library(R.ROSETTA)
# Load the dataset with original names preserved
data_original <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Spambase/spambase_train2_binned.csv", header = T,check.names = FALSE)
# Load the dataset with R's default name checking
data_modified <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Spambase/spambase_train2_binned.csv", header = T, check.names = TRUE)
# Create a dataframe that maps original names to modified names
name_comparison <- data.frame(
Original_Names = names(data_original),
Modified_Names = names(data_modified)
)
# Print the comparison dataframe
print(name_comparison)
# load data
dat <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Spambase/spambase_train2_binned.csv", header = T, colClasses = "character")
# Check column names
print(names(dat))
# Summary to check for any obvious issues in data
summary(dat)
# change names of truth and prediction
names(dat)[dim(dat)[2] - 1] = "True"
names(dat)[dim(dat)[2]] = "Prediction"
# extract true labels
truth <- dat[,(dim(dat)[2] - 1)]
# remove truth label from data frame
df <- dat[,c(1:(dim(dat)[2] - 2), dim(dat)[2])]
# run Rosetta on all three data frame
ros <- rosetta(df, discrete = T, underSample = T, reducer = "Johnson")
# load necessary packages
library(dplyr)
library(R.ROSETTA)
# Load the dataset with original names preserved
data_original <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Spambase/spambase_train2_binned.csv", header = T,check.names = FALSE)
# Load the dataset with R's default name checking
data_modified <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Spambase/spambase_train2_binned.csv", header = T, check.names = TRUE)
# Create a dataframe that maps original names to modified names
name_comparison <- data.frame(
Original_Names = names(data_original),
Modified_Names = names(data_modified)
)
# Print the comparison dataframe
print(name_comparison)
# load data
dat <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Spambase/spambase_train2_binned.csv", header = T, colClasses = "character")
# Check column names
print(names(dat))
# Summary to check for any obvious issues in data
summary(dat)
# change names of truth and prediction
names(dat)[dim(dat)[2] - 1] = "True"
names(dat)[dim(dat)[2]] = "Prediction"
# extract true labels
truth <- dat[,(dim(dat)[2] - 1)]
# remove truth label from data frame
df <- dat[,c(1:(dim(dat)[2] - 2), dim(dat)[2])]
# run Rosetta on all three data frame
ros <- rosetta(df, discrete = T, underSample = T, reducer = "Johnson")
testie <- recalculateRules(df,ros$main, discrete = T)
testie_rec <- distinct(testie[testie$pValue<=0.05,])
viewRules(testie_rec)
######### Replacing the wrong names with the correct ones ###############
# Split the concatenated names into a list of vectors
features_list <- strsplit(testie_rec$features, ",")
# Function to find original name for each modified name
get_original_name <- function(modified_name) {
# Trim whitespace which might be left from splitting
modified_name <- trimws(modified_name)
# Find the match in name_comparison and return the original name
index <- match(modified_name, name_comparison$Modified_Names)
if (!is.na(index)) {
return(name_comparison$Original_Names[index])
} else {
return(modified_name)  # Return the modified name if no original found
}
}
# Apply the function to each element in the list and recombine names
corrected_features <- sapply(features_list, function(feature_vector) {
original_names <- sapply(feature_vector, get_original_name)
paste(original_names, collapse = ",")
})
# Replace the original features with corrected ones
testie_rec$features <- corrected_features
# Check the results
print(testie_rec$features)
View(testie_rec)
# load test set
test <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Spambase/spambase_test_binned.csv", colClasses = "character", header = T, check.names = F)
# extract data and NN label
test_truth <- test[,(dim(test)[2] - 1)]
test_df <- test[,c(1:(dim(test)[2] - 2), dim(test)[2])]
names(test_df)[dim(test_df)[2]] <- "Prediction"
# predict classes for test data
pred <- predictClass(test_df[,1:(dim(test_df)[2] - 1)], testie_rec, discrete = T, validate = T, defClass = test_df[,dim(test_df)[2]], normalizeMethod = "rulnum")
pred$accuracy
table(pred$out[,c("currentClass", "predictedClass")])
pred_test <- predictClass(test_df[,1:(dim(test_df)[2] - 1)], testie_rec, discrete = T, validate = T, defClass = test_df[,dim(test_df)[2]], normalizeMethod = "rulnum")
pred_test$accuracy
table(pred_test$out[,c("currentClass", "predictedClass")])
# extract wrongly classified objects
wrongObj <- which(df[,dim(df)[2]] != truth)
# get supportSet as list
supportSet <- lapply(testie_rec$supportSetRHS, function(x){as.numeric(unlist(strsplit(x, ",")))})
# create heatmap to identify misclassified objects in support set of rules
rules <- list()
for(i in wrongObj){
tmp = which(unlist(lapply(supportSet, function(x){(i %in% x)})))
rules[[length(rules) + 1]] <- as.numeric(row.names(testie_rec[tmp,]))
}
r <- unlist(rules) %>% unique
x = lapply(rules, function(x){as.numeric(r %in% x)}) %>% data.frame
names(x) = wrongObj
row.names(x) <- r
heatmap(as.matrix(x), scale = "none", Colv = F, col = c("white", "black"),
xlab = "Object Number", ylab = "Rule Rank")
# Load the dataset with original names preserved
data_original <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Spambase/spambase_train2_binned.csv", header = T,check.names = FALSE)
# Load the dataset with R's default name checking
data_modified <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Spambase/spambase_train2_binned.csv", header = T, check.names = TRUE)
# Create a dataframe that maps original names to modified names
name_comparison <- data.frame(
Original_Names = names(data_original),
Modified_Names = names(data_modified)
)
# Print the comparison dataframe
print(name_comparison)
# load data
dat <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Spambase/spambase_train2_binned.csv", header = T, colClasses = "character")
# Check column names
print(names(dat))
# Summary to check for any obvious issues in data
summary(dat)
# change names of truth and prediction
names(dat)[dim(dat)[2] - 1] = "True"
names(dat)[dim(dat)[2]] = "Prediction"
# extract true labels
truth <- dat[,(dim(dat)[2] - 1)]
# remove truth label from data frame
df <- dat[,c(1:(dim(dat)[2] - 2), dim(dat)[2])]
rev_df <- dat[,c((dim(dat)[2] - 2):1, dim(dat)[2])]
# run Rosetta on all three data frame
ros <- rosetta(df, discrete = T, underSample = T, reducer = "Johnson")
rev_ros <- rosetta(rev_df, discrete = T, underSample = T, reducer = "Johnson")
comb <- data.frame(rbind(ros$main, rev_ros$main))
testie <- recalculateRules(df,ros$main, discrete = T)
rec <- recalculateRules(df, comb, discrete = T)
viewRules(rec)
View(rec)
######### Replacing the wrong names with the correct ones ###############
# Split the concatenated names into a list of vectors
features_list <- strsplit(rec$features, ",")
# Function to find original name for each modified name
get_original_name <- function(modified_name) {
# Trim whitespace which might be left from splitting
modified_name <- trimws(modified_name)
# Find the match in name_comparison and return the original name
index <- match(modified_name, name_comparison$Modified_Names)
if (!is.na(index)) {
return(name_comparison$Original_Names[index])
} else {
return(modified_name)  # Return the modified name if no original found
}
}
# Apply the function to each element in the list and recombine names
corrected_features <- sapply(features_list, function(feature_vector) {
original_names <- sapply(feature_vector, get_original_name)
paste(original_names, collapse = ",")
})
# Replace the original features with corrected ones
rec$features <- corrected_features
# Check the results
print(rec$features)
View(rec)
# load test set
test <- read.csv("/Users/victorenglof/Documents/GitHub/Interpretation_of_NN_using_RBM/Spambase/spambase_test_binned.csv", colClasses = "character", header = T, check.names = F)
# extract data and NN label
test_truth <- test[,(dim(test)[2] - 1)]
test_df <- test[,c(1:(dim(test)[2] - 2), dim(test)[2])]
names(test_df)[dim(test_df)[2]] <- "Prediction"
pred_test <- predictClass(test_df[,1:(dim(test_df)[2] - 1)], rec, discrete = T, validate = T, defClass = test_df[,dim(test_df)[2]], normalizeMethod = "rulnum")
pred_test$accuracy
table(pred_test$out[,c("currentClass", "predictedClass")])
# extract wrongly classified objects
wrongObj <- which(df[,dim(df)[2]] != truth)
# get supportSet as list
supportSet <- lapply(rec$supportSetRHS, function(x){as.numeric(unlist(strsplit(x, ",")))})
# create heatmap to identify misclassified objects in support set of rules
rules <- list()
for(i in wrongObj){
tmp = which(unlist(lapply(supportSet, function(x){(i %in% x)})))
rules[[length(rules) + 1]] <- as.numeric(row.names(rec[tmp,]))
}
r <- unlist(rules) %>% unique
x = lapply(rules, function(x){as.numeric(r %in% x)}) %>% data.frame
names(x) = wrongObj
row.names(x) <- r
heatmap(as.matrix(x), scale = "none", Colv = F, col = c("white", "black"),
xlab = "Object Number", ylab = "Rule Rank")
# based on heatmap inspect rules
hmap_rules <-viewRules(rec[c(7,127),])
heatmap(as.matrix(x), scale = "none", Colv = F, col = c("white", "black"),
xlab = "Object Number", ylab = "Rule Rank")
